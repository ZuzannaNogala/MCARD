{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LIST NR 2: Gradient methods. Automatic differentiation\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D3o71PfVMTkj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "swz0_46DMCGv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.base import RegressorMixin, BaseEstimator\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from scipy.stats import uniform\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2.1 (**10 pts**)\n",
        "* Sample `x_test`, a vector of size 50 of i.i.d $\\mathcal{U}(0,1)$ random variables and similarly compute corresponding\n",
        "\n",
        "$\\qquad$ `y_test = b_true + a_true * x_test + .1 * np.random.randn(nr_points, 1)`"
      ],
      "metadata": {
        "id": "Nwg4pYe7MhP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nr_points = 200\n",
        "np.random.seed(42)\n",
        "\n",
        "x_train = np.random.rand(nr_points, 1)\n",
        "\n",
        "a_true = 2.0\n",
        "b_true = 1.0\n",
        "\n",
        "y_train = b_true + a_true * x_train + .1 * np.random.randn(nr_points, 1)\n",
        "\n",
        "x_test = np.random.rand(50, 1)\n",
        "y_test = b_true + a_true * x_test + .1 * np.random.randn(50, 1)"
      ],
      "metadata": {
        "id": "4s95DBZOMHVc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Take the model (aka `a` and `b`) trained on `(x_train,y_train)` and compute final loss on test set, i.e.,\n",
        "$$\\textrm{loss}_{\\rm final} = {1\\over n}\\sum_{i=1}^{50} (a\\cdot x\\_{test} + b - y_{test})^2$$"
      ],
      "metadata": {
        "id": "lrqGpr06MPPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LinReg = LinearRegression()\n",
        "LinReg.fit(x_train, y_train)\n",
        "a_est = LinReg.coef_.item()\n",
        "b_est = LinReg.intercept_.item()\n",
        "\n",
        "loss_final = np.mean((a_est * x_test + b_est - y_test) ** 2) # or mean_square_error\n",
        "\n",
        "print(f\"Value of loss_final is {loss_final}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4333djhMq10",
        "outputId": "797cb8fa-1622-47a7-ee00-5b56b2e7c4ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value of loss_final is 0.01199110714351241.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Using SGD or Adam find new $a$ and $b$ minimizing function\n",
        "$$g(a,b)={1\\over n}\\sum_{i=1}^n (\\hat{y}_i-y_i)^2 + \\lambda(a^2+b^2)$$\n",
        "with $\\lambda=0.1$"
      ],
      "metadata": {
        "id": "OWuSuwkCNPMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TorchLinearRegression1D(RegressorMixin, BaseEstimator):\n",
        "\n",
        "    def __init__(self, lr=0.06, lmb=0, n_epochs=500, optimizer_name=\"Adam\", device=None):\n",
        "        \"\"\"\n",
        "        Initialize the model with hyperparameters.\n",
        "\n",
        "        Parameters:\n",
        "            lr (float): Learning rate.\n",
        "            lmb (float): Penalty value; if lmb = 0, then the standard linear regression is produced\n",
        "            n_epochs (int): Number of training epochs.\n",
        "            optimizer_name (str): Optimizer to use (\"SGD\" or \"Adam\").\n",
        "            device (torch.device): Device to run computations on. Defaults to CPU.\n",
        "        \"\"\"\n",
        "        self.lr = lr\n",
        "        self.lmb = lmb\n",
        "        self.n_epochs = n_epochs\n",
        "        self.optimizer_name = optimizer_name\n",
        "        self.device = device if device is not None else torch.device(\"cpu\")\n",
        "        self.a = None\n",
        "        self.b = None\n",
        "        self.loss_history = []\n",
        "        self.a_history = []\n",
        "        self.b_history = []\n",
        "\n",
        "    def fit(self, x_train, y_train, verbose=False):\n",
        "\n",
        "        x_train_tensor = torch.tensor(np.ravel(x_train), dtype=torch.float32, device=self.device).view(-1, 1)\n",
        "        y_train_tensor = torch.tensor(np.ravel(y_train), dtype=torch.float32, device=self.device).view(-1, 1)\n",
        "\n",
        "        # Initialize parameters a and b randomly, with gradient tracking.\n",
        "        self.a = torch.randn(1, requires_grad=True, dtype=torch.float32, device=self.device)\n",
        "        self.b = torch.randn(1, requires_grad=True, dtype=torch.float32, device=self.device)\n",
        "\n",
        "        if self.optimizer_name.lower() == \"sgd\":\n",
        "            optimizer = torch.optim.SGD([self.a, self.b], lr=self.lr)\n",
        "        elif self.optimizer_name.lower() == \"adam\":\n",
        "            optimizer = torch.optim.Adam([self.a, self.b], lr=self.lr)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported optimizer. Choose 'SGD' or 'Adam'.\")\n",
        "\n",
        "        # Reset histories\n",
        "        self.loss_history = []\n",
        "        self.a_history = []\n",
        "        self.b_history = []\n",
        "\n",
        "        # Main training loop\n",
        "        for epoch in range(self.n_epochs):\n",
        "\n",
        "            yhat = self.a * x_train_tensor + self.b\n",
        "            error = y_train_tensor - yhat\n",
        "            loss = torch.mean(error ** 2) + self.lmb * (self.a ** 2 + self.b ** 2)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Record training history every 10 epochs.\n",
        "            if epoch % 10 == 0:\n",
        "                self.loss_history.append(loss.item())\n",
        "                self.a_history.append(self.a.item())\n",
        "                self.b_history.append(self.b.item())\n",
        "                if verbose:\n",
        "                    print(f\"Epoch {epoch}: loss = {loss.item():.4f}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, x):\n",
        "\n",
        "        x_tensor = torch.tensor(np.ravel(x), dtype=torch.float32, device=self.device).view(-1, 1)\n",
        "        y_prediction = self.a * x_tensor + self.b\n",
        "        return y_prediction.detach().cpu().numpy().flatten()"
      ],
      "metadata": {
        "id": "RBXzsGykNTJu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_LT = TorchLinearRegression1D(lmb=0.1, optimizer_name=\"sgd\")\n",
        "model_LT.fit(x_train, y_train, verbose=True)\n",
        "\n",
        "print(f\"The most optimal params a and b for g(a, b) loss function\"\n",
        "      f\" are: a = {float(model_LT.a)}, b = {float(model_LT.b)}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxmqMPHYNp5P",
        "outputId": "adc9d1ee-efba-4038-a6a3-ec381a5d2944"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss = 5.0025\n",
            "Epoch 10: loss = 0.5972\n",
            "Epoch 20: loss = 0.4426\n",
            "Epoch 30: loss = 0.4204\n",
            "Epoch 40: loss = 0.4081\n",
            "Epoch 50: loss = 0.3999\n",
            "Epoch 60: loss = 0.3945\n",
            "Epoch 70: loss = 0.3909\n",
            "Epoch 80: loss = 0.3885\n",
            "Epoch 90: loss = 0.3869\n",
            "Epoch 100: loss = 0.3859\n",
            "Epoch 110: loss = 0.3852\n",
            "Epoch 120: loss = 0.3847\n",
            "Epoch 130: loss = 0.3844\n",
            "Epoch 140: loss = 0.3842\n",
            "Epoch 150: loss = 0.3841\n",
            "Epoch 160: loss = 0.3840\n",
            "Epoch 170: loss = 0.3839\n",
            "Epoch 180: loss = 0.3839\n",
            "Epoch 190: loss = 0.3839\n",
            "Epoch 200: loss = 0.3838\n",
            "Epoch 210: loss = 0.3838\n",
            "Epoch 220: loss = 0.3838\n",
            "Epoch 230: loss = 0.3838\n",
            "Epoch 240: loss = 0.3838\n",
            "Epoch 250: loss = 0.3838\n",
            "Epoch 260: loss = 0.3838\n",
            "Epoch 270: loss = 0.3838\n",
            "Epoch 280: loss = 0.3838\n",
            "Epoch 290: loss = 0.3838\n",
            "Epoch 300: loss = 0.3838\n",
            "Epoch 310: loss = 0.3838\n",
            "Epoch 320: loss = 0.3838\n",
            "Epoch 330: loss = 0.3838\n",
            "Epoch 340: loss = 0.3838\n",
            "Epoch 350: loss = 0.3838\n",
            "Epoch 360: loss = 0.3838\n",
            "Epoch 370: loss = 0.3838\n",
            "Epoch 380: loss = 0.3838\n",
            "Epoch 390: loss = 0.3838\n",
            "Epoch 400: loss = 0.3838\n",
            "Epoch 410: loss = 0.3838\n",
            "Epoch 420: loss = 0.3838\n",
            "Epoch 430: loss = 0.3838\n",
            "Epoch 440: loss = 0.3838\n",
            "Epoch 450: loss = 0.3838\n",
            "Epoch 460: loss = 0.3838\n",
            "Epoch 470: loss = 0.3838\n",
            "Epoch 480: loss = 0.3838\n",
            "Epoch 490: loss = 0.3838\n",
            "The most optimal params a and b for g(a, b) loss function are: a = 1.2475669384002686, b = 1.2462921142578125.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Optimize    for `lambda>0` using `GridSearch` or `RandomizedSearch`. For fixed $\\lambda$ find $\\textrm{argmin}_{a,b} g(a,b)$ on the training set, and compute the $\\textrm{loss}_{\\rm final}$ on test set. Choose $\\lambda$ that yields lowest $\\textrm{loss}_{\\rm final}$. Compare with $\\lambda=0$ (i.e., original model)."
      ],
      "metadata": {
        "id": "Ro2BJsU2N0ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_grid = {'lmb': [0.0001, 0.001, 0.01, 0.1, 0.2]}\n",
        "\n",
        "model = TorchLinearRegression1D(lr=0.1, n_epochs=1000)\n",
        "\n",
        "grid_search = GridSearchCV(model, lambda_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "y_hat = grid_search.fit(x_train, y_train).predict(x_test)\n",
        "\n",
        "loss_final_cv = mean_squared_error(y_test, y_hat)\n",
        "\n",
        "model_2 = TorchLinearRegression1D(lr=0.1, lmb=grid_search.best_params_['lmb'], n_epochs=1000, optimizer_name=\"sgd\")\n",
        "model_2.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "print(f\"The best lambda: {grid_search.best_params_['lmb']}, the loss_final: {loss_final_cv}\")\n",
        "print(f\"Then the best parameters a and b are: a = {model_2.a.item()}, b = {model_2.b.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0270U3DEN4VY",
        "outputId": "635c41a5-a011-4760-986b-f35a5007a8b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best lambda: 0.0001, the loss_final: 0.012030831831220177\n",
            "Then the best parameters a and b are: a = 1.9904531240463257, b = 1.0112613439559937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2.2 (**10 pts**)\n",
        "On previous list we considered Ridge Regression for 1d data (exact solution was provided). Now consider Ridge Regresion for multidimensional data:\n",
        "We are given data points\n",
        "$$(\\textbf{x}_1,y_1),\\ldots,(\\textbf{x}_n,y_n)$$\n",
        "where each $x_i \\in \\mathbb{R}^d$, and our goal is to estimate parameters $\\beta_0, \\ldots, \\beta_d$  such that the model\n",
        "$$\n",
        "y = \\beta_0 + \\beta_1 x_1+\\ldots +\\beta_d x_d\n",
        "$$\n",
        "\"best\" fits the data. By \"best\" we mean that the parameters minimize the loss function\n",
        "$$\n",
        "g(\\beta_0,\\beta_1,\\ldots,\\beta_d, \\lambda)=\\sum_{i=1}^n \\Bigl(y_i-(\\beta_0+\\mathbf{x}_i^T \\boldsymbol{\\beta})\\Bigr)^2 +\\lambda\\sum_{i=0}^d \\beta_i^2,\n",
        "$$\n",
        "where $\\boldsymbol{\\beta} = (\\beta_1, \\beta_2, \\ldots, \\beta_d)^T$ and $\\mathbf{x}_i=(x_{i1},\\ldots,x_{id})^T$  and $\\lambda\\geq 0$ is a hyperparamter.\n",
        "* a) Implement multidimensional Ridge Regression `myRidgeRegression_multiD()` using gradient method (note: just form of loss function is needed, make options `sgd` and `adam` available). Preferred: implementation using a class."
      ],
      "metadata": {
        "id": "ja_O5zwYOUO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myRidgeRegression_multiD(RegressorMixin, BaseEstimator):\n",
        "\n",
        "    def __init__(self, lr=0.06, lmb=0, n_epochs=500, optimizer_name=\"Adam\", device=None):\n",
        "\n",
        "        self.lr = lr\n",
        "        self.lmb = lmb\n",
        "        self.n_epochs = n_epochs\n",
        "        self.optimizer_name = optimizer_name\n",
        "        self.device = device if device is not None else torch.device(\"cpu\")\n",
        "        self.params = None\n",
        "        self.loss_history = []\n",
        "        self.params_history = []\n",
        "\n",
        "    def fit(self, x_train, y_train, verbose=False):\n",
        "\n",
        "        x_train_tensor = torch.tensor(np.c_[np.ones((x_train.shape[0], 1)), x_train], dtype=torch.float32,\n",
        "                                      device=self.device).view(x_train.shape[0], x_train.shape[1] + 1)\n",
        "\n",
        "        y_train_tensor = torch.tensor(np.ravel(y_train), dtype=torch.float32, device=self.device).view(-1, 1)\n",
        "\n",
        "        self.params = torch.nn.Parameter(torch.randn(x_train_tensor.shape[1], 1, dtype=torch.float32, device=self.device))\n",
        "\n",
        "        if self.optimizer_name.lower() == \"sgd\":\n",
        "            optimizer = torch.optim.SGD([self.params], lr=self.lr)\n",
        "        elif self.optimizer_name.lower() == \"adam\":\n",
        "            optimizer = torch.optim.Adam([self.params], lr=self.lr)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported optimizer. Choose 'SGD' or 'Adam'.\")\n",
        "\n",
        "        # Reset histories\n",
        "        self.loss_history = []\n",
        "        self.params_history = []\n",
        "\n",
        "        # Main training loop\n",
        "        for epoch in range(self.n_epochs):\n",
        "            yhat = torch.matmul(x_train_tensor, self.params)\n",
        "            error = y_train_tensor - yhat\n",
        "            loss = torch.mean(torch.pow(error, 2)) + self.lmb * torch.sum(torch.pow(self.params, 2))\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                self.loss_history.append(loss.item())\n",
        "                self.params_history.append([self.params[i] for i in range(len(self.params))])\n",
        "                if verbose:\n",
        "                    print(f\"Epoch {epoch}: loss = {loss.item():.4f}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, x):\n",
        "        x_tensor = torch.tensor(np.c_[np.ones((x.shape[0], 1)), x], dtype=torch.float32,\n",
        "                                device=self.device).view(x.shape[0], x.shape[1] + 1)\n",
        "        y_prediction = x_tensor @ self.params\n",
        "        return y_prediction.detach().cpu().numpy().flatten()"
      ],
      "metadata": {
        "id": "xEZ5G72DOcbA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ridge_reg = myRidgeRegression_multiD(lr=0.01, lmb=0.0001, n_epochs=1000)\n",
        "model_ridge_reg.fit(x_train, y_train)\n",
        "print(f\"myRidgeRegression_multiD model's parameters: b0 = {model_ridge_reg.params[0].item()}, b1 = {model_ridge_reg.params[1].item()}\")\n",
        "\n",
        "# print(model_ridge_reg.params)\n",
        "\n",
        "model_torch = TorchLinearRegression1D(lr=0.01, lmb=0.0001, n_epochs=1000)\n",
        "model_torch.fit(x_train, y_train)\n",
        "print(f\"TorchLinearRegression1D model's parameters: b0 = {model_torch.b.item()}, b1 = {model_torch.a.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbVPBwxKPEoC",
        "outputId": "2ca521c1-1458-4155-9c0f-8d069fd9e6b8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "myRidgeRegression_multiD model's parameters: b0 = 1.1168948411941528, b1 = 1.7935035228729248\n",
            "TorchLinearRegression1D model's parameters: b0 = 1.0186325311660767, b1 = 1.9764670133590698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* b) Re-consider California House Pricing from previous list. Choose several values of $\\lambda$ and compare results with `myLinearRegression_multiD()`"
      ],
      "metadata": {
        "id": "SOdlG0RrTm5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myLinearRegression_multiD:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.betas = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        matrix_plan = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "        self.betas = np.linalg.inv(matrix_plan.T @ matrix_plan) @ matrix_plan.T @ y\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        matrix_plan = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "        return np.ravel(matrix_plan @ self.betas)\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {}\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        for key, value in params.items():\n",
        "            setattr(self, key, value)\n",
        "        return self"
      ],
      "metadata": {
        "id": "PdLEmRkETuwE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "Y = data.target\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "JP5cVUnCT5N0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_grid = {'lmb': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 2]}\n",
        "\n",
        "model = myRidgeRegression_multiD(lr=0.01, n_epochs=1000)\n",
        "grid_search = GridSearchCV(model, lambda_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, Y_train)\n",
        "y_hat = grid_search.best_estimator_.predict(X_test)\n",
        "\n",
        "print(grid_search.cv_results_.get('mean_test_score'))\n",
        "\n",
        "print(\"GridSearchCV best lambda:\", grid_search.best_params_['lmb'])\n",
        "print(\"GridSearchCV best CV MSE:\", -grid_search.best_score_)\n",
        "print(\"GridSearchCV best CV MSE (test set):\", mean_squared_error(Y_test, y_hat))\n",
        "\n",
        "model_linear_reg = myLinearRegression_multiD()\n",
        "Y_prediction = model_linear_reg.fit(X_train, Y_train).predict(X_test)\n",
        "\n",
        "print(f\"MSE of linear model (test set): {mean_squared_error(Y_test, Y_prediction)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCsA58vnUEUx",
        "outputId": "749089cb-5d9c-4905-8ebf-d08be4177d2e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1863.76497464 -4573.09229025  -131.00720877  -221.627834\n",
            "  -179.55472273 -1633.46239376  -336.48990995]\n",
            "GridSearchCV best lambda: 0.01\n",
            "GridSearchCV best CV MSE: 131.007208772179\n",
            "GridSearchCV best CV MSE (test set): 16.46951382891158\n",
            "MSE of linear model: 0.5558915986959397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* c) Find \"best\" parameter lambda using `RandomizedSearchCV` (your implementation of `myRidgeRegression_multiD()` may require modification), search for it using uniform(0,5) distr., `cv=5` and `n_iter=100`. Compare model with best $\\lambda$ found this way with previous models.\n"
      ],
      "metadata": {
        "id": "2cOF3XO-VLvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_dist = {'lmb': uniform(0, 5)}\n",
        "model_3 = myRidgeRegression_multiD(lr=0.01, n_epochs=1000)\n",
        "\n",
        "random_search = RandomizedSearchCV(model_3, lambda_dist, cv=5, scoring='neg_mean_squared_error',\n",
        "                                   n_iter=100, random_state=42)\n",
        "random_search.fit(X_train, Y_train)\n",
        "\n",
        "print(\"RandomizedSearchCV best lambda:\", random_search.best_params_['lmb'])\n",
        "print(\"RandomizedSearchCV best CV MSE:\", -random_search.best_score_)\n",
        "\n",
        "Y_hat = random_search.best_estimator_.predict(X_test)\n",
        "\n",
        "print(\"RandomizedSearchCV best CV MSE (test set):\", mean_squared_error(Y_test, Y_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nYP7m19VQZf",
        "outputId": "0c5cba14-8f98-40fa-a8d3-24a6445da3fa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomizedSearchCV best lambda: 3.005575058716044\n",
            "RandomizedSearchCV best CV MSE: 22.516970733532396\n",
            "RandomizedSearchCV best CV MSE (test set): 260.6386655215918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2.3 (**10 pts**)\n",
        "Consider matrix $Z$:\n",
        "\n",
        "```python\n",
        "d=15\n",
        "n=11\n",
        "Z = torch.randint(0,10,(n,d))\n",
        "print(Z)\n",
        "```\n",
        "\n",
        " $$dist_{Frob}(\\mathbf{Z},\\mathbf{W}\\mathbf{H})=||\\mathbf{Z}-\\mathbf{W}\\mathbf{H}||^2=\\sum_{i,j} (\\mathbf{Z}[i,j] -(\\mathbf{W}\\mathbf{H})[i,j])^2$$\n",
        "\n",
        "A)\n",
        "* Perform Truncated SVD, i.e., decompose $\\mathbf{Z}=\\mathbf{U}\\mathbf{\\Lambda}^{1\\over 2} \\mathbf{V}^T$, denote $\\mathbf{W}=\\mathbf{U}, \\mathbf{H}=\\mathbf{\\Lambda}^{1\\over 2} \\mathbf{V}^T$. Then approximate $\\mathbf{Z}$ by $\\mathbf{Z}_r=\\mathbf{W}_r \\mathbf{H}_r$. Compare with SGD/Adam methods for various values of $r$. What are the conclusions?"
      ],
      "metadata": {
        "id": "j3LKYGN8Wwom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = 15\n",
        "n = 11\n",
        "Z = torch.randint(0, 10, (n, d), dtype=torch.float32)\n",
        "\n",
        "W, Lmb, V = torch.svd(Z)\n",
        "H = torch.matmul(torch.diag(Lmb), V.T)\n",
        "# print(\"Z Shape: \", Z.shape)\n",
        "# print(\"H Shape: \", H.shape)\n",
        "# print(\"U Shape: \", W.shape)\n",
        "# print(\"V Shape: \", V.shape)"
      ],
      "metadata": {
        "id": "iYgUYFZRW6Ie"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greater_than_half(torch_Matrix):\n",
        "    with torch.no_grad():\n",
        "        elements_to_fix = torch_Matrix < 0.5\n",
        "        torch_Matrix[elements_to_fix] = 0.501\n",
        "    return torch_Matrix"
      ],
      "metadata": {
        "id": "r8JAm137uXE9"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Recovering:\n",
        "\n",
        "    def __init__(self, lr=0.06, n_epochs=500, optimizer_name=\"Adam\",device=None):\n",
        "        self.lr = lr\n",
        "        self.n_epochs = n_epochs\n",
        "        self.optimizer_name = optimizer_name\n",
        "        self.W_r = None\n",
        "        self.H_r = None\n",
        "        self.device = device if device is not None else torch.device(\"cpu\")\n",
        "        self.loss_list = []\n",
        "\n",
        "    def fit(self, Z, r, dist_pow, verbose=True):\n",
        "        self.loss_list = []\n",
        "\n",
        "        W_r = torch.randn((Z.shape[0], r), requires_grad=True, dtype=torch.float, device=self.device)\n",
        "        H_r = torch.randn((r, Z.shape[1]), requires_grad=True, dtype=torch.float, device=self.device)\n",
        "\n",
        "        if self.optimizer_name.lower() == \"sgd\":\n",
        "            optimizer = torch.optim.SGD([W_r, H_r], lr=self.lr)\n",
        "        elif self.optimizer_name.lower() == \"adam\":\n",
        "            optimizer = torch.optim.Adam([W_r, H_r], lr=self.lr)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported optimizer. Choose 'SGD' or 'Adam'.\")\n",
        "\n",
        "        for epoch in range(self.n_epochs):\n",
        "\n",
        "            loss = torch.mean(torch.pow(Z - torch.matmul(W_r, H_r), dist_pow))\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                self.loss_list.append(loss.item())\n",
        "                if verbose:\n",
        "                    print(f\"Epoch {epoch}: loss = {loss.item():.4f}\")\n",
        "\n",
        "        self.W_r = W_r\n",
        "        self.H_r = H_r\n",
        "\n",
        "    def fit_H_greater_than_half(self, Z, r, dist_pow, verbose=True):\n",
        "        self.loss_list = []\n",
        "\n",
        "        W_r = torch.randn((Z.shape[0], r), requires_grad=True, dtype=torch.float, device=self.device)\n",
        "        H_r = torch.randn((r, Z.shape[1]), requires_grad=True, dtype=torch.float, device=self.device)\n",
        "\n",
        "        if self.optimizer_name.lower() == \"sgd\":\n",
        "            optimizer = torch.optim.SGD([W_r, H_r], lr=self.lr)\n",
        "        elif self.optimizer_name.lower() == \"adam\":\n",
        "            optimizer = torch.optim.Adam([W_r, H_r], lr=self.lr)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported optimizer. Choose 'SGD' or 'Adam'.\")\n",
        "\n",
        "        for epoch in range(self.n_epochs):\n",
        "            H2_r = greater_than_half(H_r)\n",
        "\n",
        "            loss = torch.mean(torch.pow(Z - torch.matmul(W_r, H2_r), dist_pow))\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                self.loss_list.append(loss.item())\n",
        "                if verbose:\n",
        "                    print(f\"Epoch {epoch}: loss = {loss.item():.4f}\")\n",
        "\n",
        "        self.W_r = W_r\n",
        "        self.H_r = greater_than_half(H_r)\n",
        "\n",
        "    def fit_nonnegativeW(self, Z, r, dist_pow, verbose=True):\n",
        "        self.loss_list = []\n",
        "\n",
        "        W_r = torch.randn((Z.shape[0], r), requires_grad=True, dtype=torch.float, device=self.device)\n",
        "        H_r = torch.randn((r, Z.shape[1]), requires_grad=True, dtype=torch.float, device=self.device)\n",
        "\n",
        "        if self.optimizer_name.lower() == \"sgd\":\n",
        "            optimizer = torch.optim.SGD([W_r, H_r], lr=self.lr)\n",
        "        elif self.optimizer_name.lower() == \"adam\":\n",
        "            optimizer = torch.optim.Adam([W_r, H_r], lr=self.lr)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported optimizer. Choose 'SGD' or 'Adam'.\")\n",
        "\n",
        "        for epoch in range(self.n_epochs):\n",
        "            W2_r = torch.exp(W_r)\n",
        "\n",
        "            loss = torch.mean(torch.pow(Z - torch.matmul(W2_r, H_r), dist_pow))\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                self.loss_list.append(loss.item())\n",
        "                if verbose:\n",
        "                    print(f\"Epoch {epoch}: loss = {loss.item():.4f}\")\n",
        "\n",
        "        self.W_r = torch.exp(W_r)\n",
        "        self.H_r = H_r\n",
        "\n",
        "    def get_recovered_Z(self):\n",
        "        return torch.matmul(self.W_r, self.H_r)"
      ],
      "metadata": {
        "id": "CMDdtt1DXDQB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rdist2 = Recovering(lr=0.02, n_epochs=1000)\n",
        "loss_dic_dist2 = {}\n",
        "\n",
        "for r in range(1, 12):\n",
        "    Rdist2.fit(Z, r, dist_pow=2, verbose=False)\n",
        "    loss_dic_dist2[r] = Rdist2.loss_list[-1]\n",
        "    print(f\" The loss for r = {r} = {Rdist2.loss_list[-1]}\")\n",
        "\n",
        "plt.plot(loss_dic_dist2.keys(), loss_dic_dist2.values(), label=\"power = 2 (Frob)\")\n",
        "plt.title(\"Value of loss for various r (Frob distance)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "KbV1YHJ0XUYW",
        "outputId": "49ca428e-9de9-4b6d-c488-49c6eb1e4028"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The loss for r = 1 = 6.973441123962402\n",
            " The loss for r = 2 = 5.355447292327881\n",
            " The loss for r = 3 = 3.900682210922241\n",
            " The loss for r = 4 = 2.678865432739258\n",
            " The loss for r = 5 = 1.7005555629730225\n",
            " The loss for r = 6 = 1.1348755359649658\n",
            " The loss for r = 7 = 0.6111811399459839\n",
            " The loss for r = 8 = 0.3625536561012268\n",
            " The loss for r = 9 = 0.182081401348114\n",
            " The loss for r = 10 = 0.050418708473443985\n",
            " The loss for r = 11 = 0.00022185331908985972\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Consider different distance\n",
        " $$dist_{4}(\\mathbf{Z},\\mathbf{W}\\mathbf{H})=\\sum_{i,j} (\\mathbf{Z}[i,j] -(\\mathbf{W}\\mathbf{H})[i,j])^4$$\n",
        " Find \"best\" matrices $\\mathbf{W}, \\mathbf{H}$ using SGD/Adam methods. Compare with distance computed for truncated SVD."
      ],
      "metadata": {
        "id": "A1aDixUEaXe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rdist4 = Recovering(lr=0.02, n_epochs=1000)\n",
        "loss_dic_dist4 = {}\n",
        "\n",
        "for r in range(1, 12):\n",
        "    Rdist4.fit(Z, r, dist_pow=4, verbose=False)\n",
        "    loss_dic_dist4[r] = Rdist4.loss_list[-1]\n",
        "    print(f\" The loss for r = {r} = {Rdist4.loss_list[-1]}\")\n",
        "\n",
        "plt.plot(loss_dic_dist2.keys(), loss_dic_dist2.values(), label=r'$\\text{dist}_2$')\n",
        "plt.plot(loss_dic_dist4.keys(), loss_dic_dist4.values(), label=r'$\\text{dist}_4$')\n",
        "plt.title(r'Comparison of value of loss with $dist_2$ and $dist_4$ for various r')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "YsTbn3jUXfKv",
        "outputId": "ac8ddb5f-2027-4f77-b320-0db2c9ea9a68"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The loss for r = 1 = 91.84764099121094\n",
            " The loss for r = 2 = 61.69110870361328\n",
            " The loss for r = 3 = 40.41175079345703\n",
            " The loss for r = 4 = 22.0336971282959\n",
            " The loss for r = 5 = 11.239727973937988\n",
            " The loss for r = 6 = 4.905696868896484\n",
            " The loss for r = 7 = 1.8864262104034424\n",
            " The loss for r = 8 = 1.0574413537979126\n",
            " The loss for r = 9 = 1.1756765842437744\n",
            " The loss for r = 10 = 0.5638241171836853\n",
            " The loss for r = 11 = 0.2923405170440674\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B)\n",
        "* Approximate the same  $\\mathbf{Z}$ as\n",
        "$$\\mathbf{Z}\\approx \\mathbf{W}\\mathbf{H}$$\n",
        "where $\\mathbf{W}$ is of size $n\\times r$ and $\\mathbf{H}$ is of size $r\\times d$ (fix some $r<d$) so that\n",
        "* a) $\\mathbf{W}$ is a symmetric matrix\n",
        "* b) $\\mathbf{W}$ is a symmetric matrix with nonnegative entries\n",
        "* c) $\\mathbf{W}$ is symmetric and each entry of $\\mathbf{H}$ is at least 0.5"
      ],
      "metadata": {
        "id": "VE8XNKQ1b1C8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rb = Recovering(lr=0.02, n_epochs=1000)\n",
        "for r in range(1, 8):\n",
        "    Rb.fit_nonnegativeW(Z, r, dist_pow=2, verbose=False)\n",
        "    print(f\" The loss for r = {r} = {Rb.loss_list[-1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNlibJMyb2DI",
        "outputId": "62c729ec-9219-4b59-831c-56ae1033bcdd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The loss for r = 1 = 6.973442077636719\n",
            " The loss for r = 2 = 5.357255935668945\n",
            " The loss for r = 3 = 3.9097483158111572\n",
            " The loss for r = 4 = 2.678877592086792\n",
            " The loss for r = 5 = 1.7088077068328857\n",
            " The loss for r = 6 = 1.1383548974990845\n",
            " The loss for r = 7 = 0.6123573780059814\n",
            " The loss for r = 8 = 0.36936303973197937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Z matrix: {Z}\")\n",
        "print(f\"Recovered Z matrix: {Rb.get_recovered_Z()}\")\n",
        "print(f\"Nonnegative elements of W_r matrix: {Rb.W_r > 0}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKDzRq6Huykh",
        "outputId": "9b14fad8-2f3e-496e-85b0-02b85aa9f86f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z matrix: tensor([[9., 5., 4., 8., 5., 2., 2., 1., 7., 4., 2., 2., 4., 1., 7.],\n",
            "        [5., 8., 2., 5., 0., 6., 7., 6., 6., 7., 7., 9., 1., 1., 3.],\n",
            "        [5., 1., 8., 1., 4., 3., 0., 2., 8., 3., 8., 0., 1., 1., 0.],\n",
            "        [5., 5., 7., 2., 6., 2., 5., 0., 6., 9., 3., 9., 3., 1., 6.],\n",
            "        [2., 6., 1., 9., 7., 8., 0., 6., 4., 3., 8., 8., 3., 6., 8.],\n",
            "        [5., 3., 1., 0., 5., 6., 9., 8., 2., 7., 9., 6., 5., 8., 3.],\n",
            "        [6., 6., 3., 3., 7., 5., 0., 7., 2., 6., 3., 7., 0., 8., 6.],\n",
            "        [2., 3., 0., 6., 0., 3., 9., 4., 2., 8., 4., 2., 4., 5., 2.],\n",
            "        [1., 1., 8., 3., 3., 6., 9., 8., 8., 5., 3., 0., 2., 2., 4.],\n",
            "        [3., 1., 5., 0., 6., 5., 1., 8., 9., 0., 2., 3., 3., 7., 7.],\n",
            "        [4., 5., 3., 0., 6., 2., 1., 0., 3., 8., 9., 0., 3., 8., 8.]])\n",
            "Recovered Z matrix: tensor([[ 8.9484,  4.9053,  4.1434,  8.2072,  4.8567,  2.4096,  1.7525,  0.7761,\n",
            "          7.0962,  4.3935,  1.6793,  1.9701,  3.7671,  1.4049,  6.6064],\n",
            "        [ 4.7910,  6.6776,  2.6905,  5.9588,  1.5149,  6.1455,  7.0734,  5.7144,\n",
            "          5.0136,  7.0981,  7.0525,  9.5398,  1.6661,  0.8263,  1.9673],\n",
            "        [ 5.1665,  1.5003,  7.4906,  0.2725,  3.6386,  3.2044,  0.3086,  1.9319,\n",
            "          8.2480,  2.5067,  8.2071, -0.1622,  1.0851,  0.5425,  0.8537],\n",
            "        [ 5.1951,  5.9640,  7.0718,  1.7820,  5.3018,  1.8339,  4.7970,  0.6299,\n",
            "          6.0268,  9.3765,  2.7957,  8.2820,  1.9196,  1.1157,  6.3750],\n",
            "        [ 2.1174,  6.8908,  0.9292,  8.7519,  6.0778,  7.7141, -0.2649,  6.4936,\n",
            "          4.3969,  3.3475,  7.7988,  7.4651,  2.1283,  6.3588,  8.3118],\n",
            "        [ 5.0689,  3.8242,  1.2580,  0.1249,  3.9558,  5.9982,  8.3740,  8.4499,\n",
            "          2.3366,  7.9173,  8.4473,  5.3466,  3.6905,  8.8242,  2.7698],\n",
            "        [ 5.8479,  5.3271,  1.8030,  2.1076,  7.0844,  4.8924,  0.7221,  5.9795,\n",
            "          2.9724,  4.4864,  3.7637,  8.1491,  2.1364,  7.4012,  6.8067],\n",
            "        [ 2.2528,  3.3387, -0.3157,  5.3381,  0.3242,  3.4665,  9.5785,  3.9916,\n",
            "          1.5812,  7.3487,  4.3290,  1.7157,  4.0747,  3.9921,  2.9519],\n",
            "        [ 0.7477,  0.6303,  7.4454,  2.8512,  2.5723,  5.3138,  8.9849,  7.5982,\n",
            "          9.0483,  4.5705,  3.2262,  0.7878,  3.0473,  2.4423,  3.9361],\n",
            "        [ 3.1423,  0.8359,  5.9444,  0.6828,  7.0646,  5.4853,  0.9732,  8.4536,\n",
            "          7.5078,  0.5625,  1.7897,  2.4196,  2.1392,  6.5781,  6.5213],\n",
            "        [ 3.8003,  4.0472,  3.3584,  0.6363,  6.9039,  1.9030,  1.0196, -0.2356,\n",
            "          2.5805,  8.0089,  9.0717,  0.5144,  3.6330,  8.0214,  7.2600]],\n",
            "       grad_fn=<MmBackward0>)\n",
            "Nonnegative elements of W_r matrix: tensor([[True, True, True, True, True, True, True, True],\n",
            "        [True, True, True, True, True, True, True, True],\n",
            "        [True, True, True, True, True, True, True, True],\n",
            "        [True, True, True, True, True, True, True, True],\n",
            "        [True, True, True, True, True, True, True, True],\n",
            "        [True, True, True, True, True, True, True, True],\n",
            "        [True, True, True, True, True, True, True, True],\n",
            "        [True, True, True, True, True, True, True, True],\n",
            "        [True, True, True, True, True, True, True, True],\n",
            "        [True, True, True, True, True, True, True, True],\n",
            "        [True, True, True, True, True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rc = Recovering(lr=0.02, n_epochs=1000)\n",
        "for r in range(1, 9):\n",
        "    Rc.fit_H_greater_than_half(Z, r, dist_pow=2, verbose=False)\n",
        "    print(f\" The loss for r = {r} = {Rc.loss_list[-1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb6h-Z-BvNH2",
        "outputId": "2b7ef93a-3e25-4169-df3e-defbb8c7e680"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The loss for r = 1 = 6.973442077636719\n",
            " The loss for r = 2 = 5.50858736038208\n",
            " The loss for r = 3 = 3.935673475265503\n",
            " The loss for r = 4 = 2.6868784427642822\n",
            " The loss for r = 5 = 1.709101676940918\n",
            " The loss for r = 6 = 1.167107105255127\n",
            " The loss for r = 7 = 0.6111830472946167\n",
            " The loss for r = 8 = 0.36261799931526184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Z matrix: {Z}\")\n",
        "print(f\"Recovered Z matrix: {Rc.get_recovered_Z()}\")\n",
        "print(f\"Elements greater than 0.5 in W_8 matrix: {Rc.H_r > 0.5}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-schuGJevazF",
        "outputId": "fcb9a06a-f769-4fe0-d774-45c437a7f13b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z matrix: tensor([[9., 5., 4., 8., 5., 2., 2., 1., 7., 4., 2., 2., 4., 1., 7.],\n",
            "        [5., 8., 2., 5., 0., 6., 7., 6., 6., 7., 7., 9., 1., 1., 3.],\n",
            "        [5., 1., 8., 1., 4., 3., 0., 2., 8., 3., 8., 0., 1., 1., 0.],\n",
            "        [5., 5., 7., 2., 6., 2., 5., 0., 6., 9., 3., 9., 3., 1., 6.],\n",
            "        [2., 6., 1., 9., 7., 8., 0., 6., 4., 3., 8., 8., 3., 6., 8.],\n",
            "        [5., 3., 1., 0., 5., 6., 9., 8., 2., 7., 9., 6., 5., 8., 3.],\n",
            "        [6., 6., 3., 3., 7., 5., 0., 7., 2., 6., 3., 7., 0., 8., 6.],\n",
            "        [2., 3., 0., 6., 0., 3., 9., 4., 2., 8., 4., 2., 4., 5., 2.],\n",
            "        [1., 1., 8., 3., 3., 6., 9., 8., 8., 5., 3., 0., 2., 2., 4.],\n",
            "        [3., 1., 5., 0., 6., 5., 1., 8., 9., 0., 2., 3., 3., 7., 7.],\n",
            "        [4., 5., 3., 0., 6., 2., 1., 0., 3., 8., 9., 0., 3., 8., 8.]])\n",
            "Recovered Z matrix: tensor([[ 8.7116,  5.1923,  4.3557,  8.3226,  4.6514,  1.9054,  1.5966,  1.1500,\n",
            "          7.1109,  4.6327,  1.7193,  1.8327,  3.3889,  1.5313,  6.6788],\n",
            "        [ 5.0039,  6.6843,  2.6545,  5.9759,  1.4918,  6.1276,  7.0718,  5.7947,\n",
            "          5.0122,  7.0820,  6.9898,  9.4686,  1.6532,  0.8697,  1.8810],\n",
            "        [ 5.2082,  1.5848,  7.5128,  0.3051,  3.5702,  3.0757,  0.2583,  2.0632,\n",
            "          8.2573,  2.5669,  8.1884, -0.2280,  0.9551,  0.6064,  0.8197],\n",
            "        [ 4.9525,  5.7826,  7.0330,  1.7178,  5.4555,  2.1143,  4.8980,  0.3054,\n",
            "          6.0345,  9.2694,  2.8922,  8.4554,  2.1554,  0.9687,  6.4895],\n",
            "        [ 1.9059,  6.6905,  0.8737,  8.6792,  6.2415,  7.9458, -0.1610,  6.1776,\n",
            "          4.4059,  3.2075,  7.8999,  7.6750,  2.4159,  6.2007,  8.4098],\n",
            "        [ 4.5209,  3.9940,  1.4691,  0.1799,  3.8884,  5.9062,  8.2905,  8.4613,\n",
            "          2.3461,  8.1561,  8.4916,  5.3219,  3.4019,  8.8350,  2.9709],\n",
            "        [ 6.4467,  5.4720,  1.7303,  2.1401,  6.9316,  4.6856,  0.6444,  6.3351,\n",
            "          2.9578,  4.5044,  3.6012,  7.9371,  1.9615,  7.5984,  6.5486],\n",
            "        [ 2.4193,  3.3631, -0.3337,  5.3588,  0.2862,  3.3585,  9.5538,  4.1089,\n",
            "          1.5533,  7.3307,  4.3222,  1.6678,  4.0630,  4.0171,  2.8824],\n",
            "        [ 1.0340,  0.4549,  7.3033,  2.7761,  2.6812,  5.5322,  9.0733,  7.4718,\n",
            "          9.0238,  4.3988,  3.2053,  0.8560,  3.2954,  2.3883,  3.8480],\n",
            "        [ 2.9819,  0.8661,  5.9949,  0.7001,  7.0487,  5.5121,  0.9635,  8.4051,\n",
            "          7.5240,  0.6175,  1.7972,  2.4118,  2.0816,  6.5639,  6.5855],\n",
            "        [ 4.0284,  3.9217,  3.2431,  0.6024,  6.9748,  1.9668,  1.0944, -0.2958,\n",
            "          2.5835,  7.8568,  9.0648,  0.5699,  3.8430,  7.9849,  7.1956]],\n",
            "       grad_fn=<MmBackward0>)\n",
            "Elements greater than 0.5 in W_8 matrix: tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True],\n",
            "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True],\n",
            "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True],\n",
            "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True],\n",
            "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True],\n",
            "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True],\n",
            "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True],\n",
            "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True]])\n"
          ]
        }
      ]
    }
  ]
}